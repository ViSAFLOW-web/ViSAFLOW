<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>ViSA-Flow: Accelerating Robot Skill Learning via Large-Scale Video Semantic Action Flow</title>
  <link rel="stylesheet" href="style.css">
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif;
      max-width: 1000px;
      margin: 50px auto;
      padding: 0 20px;
      color: #333;
      line-height: 1.6;
    }

    h1, h2 {
      color: #222;
    }

    .section {
      margin-bottom: 60px;
    }

    .video-row {
      display: flex;
      justify-content: space-between;
      gap: 20px;
      flex-wrap: wrap;
    }

    .video-col {
      flex: 1;
      min-width: 300px;
    }

    video {
      width: 100%;
      height: auto;
      border: 1px solid #ccc;
      border-radius: 4px;
    }

    .annotation {
      font-size: 0.9em;
      margin-top: 10px;
      padding-left: 20px;
    }

    .video-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 20px;
    }

    .caption {
      font-weight: bold;
      margin-bottom: 5px;
    }
  </style>
</head>
<body>

  <h1>ViSA-Flow: Accelerating Robot Skill Learning via Large-Scale Video Semantic Action Flow</h1>

  <div class="section">
    <h2>Abstract</h2>
    <p>
      Enabling robots to acquire complex manipulation skills remains a great challenge, primarily bottlenecked by the prohibitive cost of collecting large-scale robot demonstration data. Humans are able to learn efficiently by watching others interact with their environment. To bridge this gap, we introduce semantic action flow as a core intermediate representation capturing the essential spatio-temporal manipulator-object interactions, invariant to superficial visual differences. We present ViSA-Flow, a framework that learns this representation self-supervised from unlabeled large-scale video data. First, a generative model is pre-trained on semantic action flows automatically extracted from large-scale human-object interaction video data, learning a robust prior over manipulation structure. Second, this prior is efficiently adapted to a target robot by fine-tuning on a small set of robot demonstrations processed through the same semantic abstraction pipeline. We demonstrate through extensive experiments on the CALVIN benchmark and real-world tasks that ViSA-Flow achieves state-of-the-art performance, particularly in low-data regimes, outperforming prior methods by effectively transferring knowledge from human video observation to robotic execution.
    </p>
  </div>

  <div class="section">
    <h2>Simulation Videos (2x Speed)</h2>
    <div class="video-row">
      <div class="video-col">
        <video controls>
          <source src="media/calvin_successful_sequence_4_converted_2x.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <div class="annotation">
          <ol>
            <li>Open the drawer</li>
            <li>Turn off the lightbulb</li>
            <li>Rotate the red block to the right</li>
            <li>Lift the red block from the table</li>
            <li>Place the red block into the drawer</li>
          </ol>
        </div>
      </div>
      <div class="video-col">
        <video controls>
          <source src="media/calvin_successful_sequence_11_converted_2x.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <div class="annotation">
          <ol>
            <li>Open the drawer</li>
            <li>Move the slider to the right</li>
            <li>Lift the red block from the slider</li>
            <li>Place the red block into the drawer</li>
            <li>Turn off the lightbulb</li>
          </ol>
        </div>
      </div>
    </div>
  </div>

   <!-- ---------- Real‑world Videos (1× Speed) ---------- -->
   <div class="section">
    <h2>Real-world Videos (1x Speed)</h2>

    <!-- Row 1: MoveContainer -->
    <div class="video-row">
      <div class="video-col">
        <video controls>
          <source src="media/movecontainer1.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <div class="video-col">
        <video controls>
          <source src="media/movecontainer2.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <div class="video-col">
        <video controls>
          <source src="media/movecontainer3.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>
    <div class="row-caption">MoveContainer</div>

    <!-- Row 2: PickEggplant -->
    <div class="video-row" style="margin-top:40px;">
      <div class="video-col">
        <video controls>
          <source src="media/eggplant1.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <div class="video-col">
        <video controls>
          <source src="media/eggplant2.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <div class="video-col">
        <video controls>
          <source src="media/eggplant3.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>
    <div class="row-caption">PickEggplant</div>
  </div>

  <div class="section">
    <h2>Real-world Long Horizon (1x Speed)</h2>
    <video class="long-video" controls>
      <source src="media/long_horizon.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <div style="text-align: center; font-weight: bold; margin-top: 5px; margin-bottom: 30px;">
      MoveContainer → PickEggplant
    </div>
  </div>

  <!-- ---------- Real‑world flow representation comparison ---------- -->
<!-- ---------- Real‑world flow representation comparison ---------- -->
<div class="section">
  <h2>Real-world Flow Representation Comparison</h2>

  <div class="video-row four-video-row">
    <!-- 1 -->
    <div class="video-col">
      <div class="top-caption">Decoded <i>ẑ<sub>t</sub></i></div>
      <video controls>
        <source src="media/mc_decoded.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>

    <!-- 2 -->
    <div class="video-col">
      <div class="top-caption">Ground truth <i>z<sub>t</sub></i></div>
      <video controls>
        <source src="media/mc_gt.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>

    <!-- 3 -->
    <div class="video-col">
      <div class="top-caption">Decoded <i>ẑ<sub>t</sub></i></div>
      <video controls>
        <source src="media/pe_decoded.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>

    <!-- 4 -->
    <div class="video-col">
      <div class="top-caption">Ground truth <i>z<sub>t</sub></i></div>
      <video controls>
        <source src="media/pe_gt.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </div>

  <div class="caption-row">
    <span class="row-caption-half">MoveContainer</span>
    <span class="row-caption-half">PickEggplant</span>
  </div>
</div>

</body>
</html>
